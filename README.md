# ğŸ•¸ï¸ Projekt semestralny - Web Scraping
## ğŸ“„ Cel projektu

## ğŸ“Œ Opis projektu

Niniejsza aplikacja to rozproszony system do **automatycznego pobierania, selekcjonowania i przechowywania danych** z witryn internetowych, zgodnie z uprzednio zdefiniowanym **profilem danych**. Celem projektu jest stworzenie skalowalnego i modularnego narzÄ™dzia do web scrapingu, ktÃ³re moÅ¼e funkcjonowaÄ‡ w Å›rodowisku wieloprocesorowym i rozproszonym.

## ğŸ“‹ Zakres funkcjonalnoÅ›ci

- âœ… TytuÅ‚
- âœ… Kategoria
- âœ… Cena
- âœ… IloÅ›Ä‡
 

## ğŸ§± Architektura systemu

Projekt zakÅ‚ada **modularnÄ…, kontenerowÄ… architekturÄ™**, ktÃ³ra skÅ‚ada siÄ™ z minimum **3 kontenerÃ³w**:

| ModuÅ‚                    | Opis                                                    |
|-------------------------------------------------------------|-----------------------------------------------------------|
| ğŸ§  Silnik              | Komponent odpowiedzialny za scraping, analizÄ™ i przetwarzanie danych; uruchamiany w kontenerze z Pythonem i multiprocessing |
| ğŸŒ Interfejs           | Serwer aplikacji webowej â€“ obsÅ‚uguje interakcjÄ™ z uÅ¼ytkownikiem, prezentuje dane i uruchamia zadania scrapujÄ…ce |
| ğŸ—„ï¸ Baza Danych         | Redis                                                       |

## ğŸ§ª Technologie

- Python 3.x
- BeautifulSoup
- asyncio, multiprocessing
- Flask
- Redis
- Docker
- Kuberneter
## ğŸ“ Podsumowanie
## ğŸš€ Uruchamianie aplikacji

```bash
# 1. Klonowanie repozytorium
git clone https://github.com/twoj-uzytkownik/nazwa-repo.git
cd nazwa-repo

# 2. Uruchomienie kontenerÃ³w (Docker Compose)
docker-compose up --build
