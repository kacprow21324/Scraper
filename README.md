# ğŸ•¸ï¸ Projekt semestralny - Web Scraping
## ğŸ“„ Cel projektu
1. Aplikacja pobiera, selekcjonuje i skÅ‚aduje  wybranedane o narzuconym profilu z witryn internetowych.
2. Profil danych jest ustalony przez realizujÄ…cego projekt. Profil danych powinien obejmowaÄ‡ min. 4 grupy, np. adresy email, adresy korespondencyjne, schemat organizacyjny itp.
3. Program wykorzystuje wielowÄ…tkowoÅ›Ä‡/wieloprocesowoÅ›Ä‡. Silnik naleÅ¼y zrealizowaÄ‡ we wÅ‚asnym zakresie wykorzystujÄ…c: multiprocessing i asyncio. Przetwarzanie ma byÄ‡ wieloprocesowe, najlepiej z moÅ¼liwoÅ›ciÄ… skalowania na rdzenie procesora, dalej na komputery, dalej na klastry itp.
4. Do parsowania kontentu naleÅ¼y uÅ¼yÄ‡ beautifulsoup.
5. Dane majÄ… byÄ‡ zapisywane w BD, np. MongoDB
6. Program ma posiadaÄ‡ interfejs graficzny zrealizowany w Python (Flask lub Django)
7. Docelowo aplikacja ma byÄ‡ rozproszona na min 3 moduÅ‚y: interfejs (1 lub wiÄ™cej kontenerÃ³w), silnik (1 kontener), BD (1 kontener). SposÃ³b ulokowania naleÅ¼y opracowaÄ‡ we wÅ‚asnym zakresie i potrafiÄ‡ uzasadniÄ‡ wybory.
8. Oprogramowanie moÅ¼e byÄ‡ zrealizowane w grupie 1 lub 2 osobowej.
9. Projekt uznaje siÄ™ za zÅ‚oÅ¼ony, jeÅ¼eli w wyznaczonym terminie zostanie opublikowany szczegÃ³Å‚owy raport z dowiÄ…zaniem do repozytorium kodu (github) oraz zostanie zademonstrowany prowadzÄ…cemu na ostatnich zajÄ™ciach laboratoryjnych.
## ğŸ“Œ Opis projektu
Niniejsza aplikacja to rozproszony system do **automatycznego pobierania, selekcjonowania i przechowywania danych** z witryn internetowych, zgodnie z uprzednio zdefiniowanym **profilem danych**. Celem projektu jest stworzenie skalowalnego i modularnego narzÄ™dzia do web scrapingu, ktÃ³re moÅ¼e funkcjonowaÄ‡ w Å›rodowisku wieloprocesorowym i rozproszonym.

## ğŸ“‹ Zakres funkcjonalnoÅ›ci

- âœ… TytuÅ‚
- âœ… Kategoria
- âœ… Cena
- âœ… IloÅ›Ä‡
 

## ğŸ§± Architektura systemu

Projekt zakÅ‚ada **modularnÄ…, kontenerowÄ… architekturÄ™**, ktÃ³ra skÅ‚ada siÄ™ z minimum **3 kontenerÃ³w**:

| ModuÅ‚                    | Opis                                                    |
|-------------------------------------------------------------|-----------------------------------------------------------|
| ğŸ§  Silnik              | Komponent odpowiedzialny za scraping, analizÄ™ i przetwarzanie danych; uruchamiany w kontenerze z Pythonem i multiprocessing |
| ğŸŒ Interfejs           | Serwer aplikacji webowej â€“ obsÅ‚uguje interakcjÄ™ z uÅ¼ytkownikiem, prezentuje dane i uruchamia zadania scrapujÄ…ce |
| ğŸ—„ï¸ Baza Danych (Redis)        | In-memory store â€“ przechowuje dane w strukturach klucz-wartoÅ›Ä‡; moÅ¼e peÅ‚niÄ‡ rolÄ™ bufora, kolejki zadaÅ„, cacheâ€™u lub tymczasowego magazynu wynikÃ³w  |

## ğŸ§ª Technologie

- Python 3.x
- BeautifulSoup
- asyncio, multiprocessing
- Flask
- Redis
- Docker
- Kuberneter
## ğŸ“ Podsumowanie
## ğŸš€ Uruchamianie aplikacji

```bash
# 1. Klonowanie repozytorium
git clone https://github.com/twoj-uzytkownik/nazwa-repo.git
cd nazwa-repo

# 2. Uruchomienie kontenerÃ³w (Docker Compose)
docker-compose up --build
